#!/usr/bin/env python3
"""
AI-Powered Vulnerability Chatbot
Uses actual LLM models for intelligent, natural responses about security vulnerabilities
"""

import json
import re
import sys
import os
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIVulnerabilityChatbot:
    """AI-powered chatbot using LLM for vulnerability analysis"""
    
    def __init__(self, knowledge_base_file: str):
        self.knowledge_base = self._load_knowledge_base(knowledge_base_file)
        self.conversation_history = []
        self.context_window = []
        
        # Initialize AI providers
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        
        # Choose available AI provider
        self.ai_provider = self._select_ai_provider()
        
        # Create system prompt with vulnerability context
        self.system_prompt = self._create_system_prompt()
        
    def _load_knowledge_base(self, kb_file: str) -> Dict:
        """Load knowledge base from JSON file"""
        try:
            with open(kb_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"Knowledge base file not found: {kb_file}")
            return self._create_default_kb()
        except json.JSONDecodeError:
            logger.error(f"Invalid JSON in knowledge base file: {kb_file}")
            return self._create_default_kb()
    
    def _create_default_kb(self) -> Dict:
        """Create default knowledge base if file not found"""
        return {
            'target_info': {
                'website': 'example.com',
                'analysis_date': datetime.now().isoformat(),
                'total_vulnerabilities': 0
            },
            'vulnerabilities': {},
            'attack_paths': [],
            'recommendations': ['No analysis data available'],
            'severity_summary': {'Critical': 0, 'High': 0, 'Medium': 0, 'Low': 0}
        }
    
    def _select_ai_provider(self) -> str:
        """Select available AI provider"""
        if self.openai_api_key:
            return 'openai'
        elif self.anthropic_api_key:
            return 'anthropic'
        elif self.gemini_api_key:
            return 'gemini'
        else:
            logger.warning("No AI API keys found. Using fallback responses.")
            return 'fallback'
    
    def _create_system_prompt(self) -> str:
        """Create comprehensive system prompt with vulnerability context"""
        
        # Extract key information from knowledge base
        target_info = self.knowledge_base.get('target_info', {})
        vulnerabilities = self.knowledge_base.get('vulnerabilities', {})
        severity_summary = self.knowledge_base.get('severity_summary', {})
        recommendations = self.knowledge_base.get('recommendations', [])
        
        # Create detailed vulnerability context
        vuln_context = ""
        for vuln_id, vuln_data in vulnerabilities.items():
            vuln_context += f"""
- {vuln_id}: {vuln_data.get('severity', 'Unknown')} severity (CVSS: {vuln_data.get('cvss', 'N/A')})
  Service: {vuln_data.get('service', 'Unknown')}
  Description: {vuln_data.get('description', 'No description')}
  Remediation: {vuln_data.get('remediation', 'Contact security team')}
"""
        
        system_prompt = f"""You are SecureChain AI, an expert cybersecurity consultant specializing in vulnerability analysis and remediation. You have just completed a comprehensive security assessment and are now providing consultation based on the findings.

ANALYSIS CONTEXT:
Target Website: {target_info.get('website', 'Unknown')}
Analysis Date: {target_info.get('analysis_date', 'Unknown')}
Total Vulnerabilities Found: {target_info.get('total_vulnerabilities', 0)}

SEVERITY BREAKDOWN:
- Critical: {severity_summary.get('Critical', 0)} vulnerabilities
- High: {severity_summary.get('High', 0)} vulnerabilities  
- Medium: {severity_summary.get('Medium', 0)} vulnerabilities
- Low: {severity_summary.get('Low', 0)} vulnerabilities

SPECIFIC VULNERABILITIES FOUND:
{vuln_context}

TOP RECOMMENDATIONS:
{chr(10).join(f"- {rec}" for rec in recommendations[:5])}

YOUR ROLE:
You are an expert security consultant providing personalized advice based on this specific vulnerability assessment. You should:

1. **Be Conversational**: Respond naturally like a human security expert, not a rigid system
2. **Be Specific**: Reference the actual vulnerabilities found in this analysis
3. **Be Practical**: Provide actionable, step-by-step remediation guidance
4. **Be Educational**: Explain the "why" behind security recommendations
5. **Be Contextual**: Consider the specific target website and its vulnerabilities
6. **Be Prioritized**: Help users understand what to fix first based on risk

RESPONSE STYLE:
- Use natural, conversational language
- Include relevant emojis for clarity (üî¥ for critical, üü† for high, etc.)
- Provide specific examples and code snippets when helpful
- Reference industry standards (OWASP, NIST, MITRE ATT&CK) when relevant
- Ask follow-up questions to better understand user needs

SECURITY EXPERTISE AREAS:
- Vulnerability assessment and penetration testing
- Web application security (OWASP Top 10)
- Network security and infrastructure hardening
- Incident response and threat hunting
- Compliance frameworks (PCI DSS, SOC 2, ISO 27001)
- DevSecOps and secure development practices

Remember: You're consulting on THIS specific analysis, not providing generic security advice. Always reference the actual findings when relevant."""

        return system_prompt
    
    def _call_openai_api(self, user_message: str) -> str:
        """Call OpenAI GPT API"""
        try:
            import openai
            
            # Prepare conversation context
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # Add recent conversation history for context
            for msg in self.context_window[-6:]:  # Last 6 messages for context
                messages.append(msg)
            
            # Add current user message
            messages.append({"role": "user", "content": user_message})
            
            # Call OpenAI API
            client = openai.OpenAI(api_key=self.openai_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",  # Use cost-effective model
                messages=messages,
                max_tokens=1000,
                temperature=0.7,
                presence_penalty=0.1,
                frequency_penalty=0.1
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            return self._fallback_response(user_message)
    
    def _call_anthropic_api(self, user_message: str) -> str:
        """Call Anthropic Claude API"""
        try:
            # Prepare conversation context
            conversation_context = ""
            for msg in self.context_window[-4:]:  # Last 4 messages
                role = "Human" if msg["role"] == "user" else "Assistant"
                conversation_context += f"\n{role}: {msg['content']}\n"
            
            # Combine system prompt with conversation
            full_prompt = f"{self.system_prompt}\n\nConversation History:{conversation_context}\n\nHuman: {user_message}\n\nAssistant:"
            
            headers = {
                "x-api-key": self.anthropic_api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            
            data = {
                "model": "claude-3-haiku-20240307",  # Fast, cost-effective model
                "max_tokens": 1000,
                "temperature": 0.7,
                "messages": [{"role": "user", "content": full_prompt}]
            }
            
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["content"][0]["text"]
            else:
                logger.error(f"Anthropic API error: {response.status_code}")
                return self._fallback_response(user_message)
                
        except Exception as e:
            logger.error(f"Anthropic API error: {e}")
            return self._fallback_response(user_message)
    
    def _call_gemini_api(self, user_message: str) -> str:
        """Call Google Gemini API"""
        try:
            # Prepare conversation context
            conversation_context = ""
            for msg in self.context_window[-4:]:
                role = "User" if msg["role"] == "user" else "Model"
                conversation_context += f"{role}: {msg['content']}\n"
            
            full_prompt = f"{self.system_prompt}\n\nConversation History:\n{conversation_context}\n\nUser: {user_message}\n\nPlease respond as SecureChain AI:"
            
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={self.gemini_api_key}"
            
            headers = {"Content-Type": "application/json"}
            
            data = {
                "contents": [{
                    "parts": [{"text": full_prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 1000,
                    "topP": 0.8,
                    "topK": 10
                }
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                logger.error(f"Gemini API error: {response.status_code}")
                return self._fallback_response(user_message)
                
        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            return self._fallback_response(user_message)
    
    def _fallback_response(self, user_message: str) -> str:
        """Intelligent fallback response when AI APIs are unavailable"""
        user_lower = user_message.lower()
        
        # Extract key information from knowledge base
        target_info = self.knowledge_base.get('target_info', {})
        vulnerabilities = self.knowledge_base.get('vulnerabilities', {})
        severity_summary = self.knowledge_base.get('severity_summary', {})
        
        # Intelligent keyword-based responses with context
        if any(word in user_lower for word in ['hello', 'hi', 'hey', 'start']):
            return f"""Hello! I'm SecureChain AI, your cybersecurity consultant. 

I've analyzed **{target_info.get('website', 'your website')}** and found **{target_info.get('total_vulnerabilities', 0)} vulnerabilities**:
üî¥ Critical: {severity_summary.get('Critical', 0)}
üü† High: {severity_summary.get('High', 0)} 
üü° Medium: {severity_summary.get('Medium', 0)}

I can help you understand these vulnerabilities, prioritize fixes, and secure your systems. What would you like to know?"""
        
        elif any(word in user_lower for word in ['critical', 'urgent', 'severe']):
            critical_vulns = {k: v for k, v in vulnerabilities.items() if v.get('severity') == 'Critical'}
            if critical_vulns:
                response = f"üö® **CRITICAL VULNERABILITIES REQUIRING IMMEDIATE ATTENTION**\n\n"
                for vuln_id, vuln_data in critical_vulns.items():
                    response += f"**{vuln_id}** (CVSS: {vuln_data.get('cvss', 'N/A')})\n"
                    response += f"üìç Service: {vuln_data.get('service', 'Unknown')}\n"
                    response += f"üõ†Ô∏è Fix: {vuln_data.get('remediation', 'Update immediately')}\n\n"
                response += "These vulnerabilities could allow attackers to completely compromise your system. **Patch immediately!**"
                return response
            else:
                return "‚úÖ Good news! No critical vulnerabilities were found in your analysis."
        
        elif 'log4j' in user_lower or 'cve-2021-44228' in user_lower:
            if 'CVE-2021-44228' in vulnerabilities:
                return """üö® **LOG4J VULNERABILITY DETECTED (CVE-2021-44228)**

This is the infamous "Log4Shell" vulnerability - one of the most severe security flaws ever discovered.

**Why it's dangerous:**
- Allows complete remote code execution
- Attackers can take full control of your server
- Being actively exploited in the wild

**IMMEDIATE ACTIONS:**
1. üîÑ Update Log4j to version 2.17.0 or later
2. üõ°Ô∏è If you can't update immediately:
   ```bash
   # Remove the vulnerable class
   zip -q -d log4j-core-*.jar org/apache/logging/log4j/core/lookup/JndiLookup.class
   ```
3. üîç Set system property: `-Dlog4j2.formatMsgNoLookups=true`
4. üö® Monitor for exploitation attempts

**This cannot wait - patch now!**"""
            else:
                return "‚úÖ Log4j vulnerability (CVE-2021-44228) was not found in your analysis."
        
        elif any(word in user_lower for word in ['fix', 'remediate', 'patch', 'solve']):
            recommendations = self.knowledge_base.get('recommendations', [])
            response = f"üõ†Ô∏è **REMEDIATION ROADMAP FOR {target_info.get('website', 'YOUR WEBSITE')}**\n\n"
            
            if severity_summary.get('Critical', 0) > 0:
                response += f"üö® **IMMEDIATE (0-24 hours):** Fix {severity_summary['Critical']} critical vulnerabilities\n"
            if severity_summary.get('High', 0) > 0:
                response += f"üü† **URGENT (1-7 days):** Address {severity_summary['High']} high-severity issues\n"
            if severity_summary.get('Medium', 0) > 0:
                response += f"üü° **IMPORTANT (1-4 weeks):** Resolve {severity_summary['Medium']} medium-severity vulnerabilities\n"
            
            response += "\n**Specific Actions:**\n"
            for i, rec in enumerate(recommendations[:5], 1):
                response += f"{i}. {rec}\n"
            
            return response
        
        elif any(word in user_lower for word in ['attack', 'exploit', 'hacker']):
            return f"""üï∏Ô∏è **POTENTIAL ATTACK SCENARIOS FOR {target_info.get('website', 'YOUR WEBSITE')}**

Based on the vulnerabilities found, here's how attackers might target you:

**üî¥ High-Risk Attack Path:**
1. **Initial Access:** Exploit web application vulnerabilities (HTTP/HTTPS services)
2. **Code Execution:** Use critical vulnerabilities like Log4j for remote code execution  
3. **Persistence:** Install backdoors to maintain access
4. **Lateral Movement:** Explore your internal network
5. **Data Theft:** Steal sensitive information or install ransomware

**üõ°Ô∏è Your Defense Strategy:**
- Patch critical vulnerabilities immediately (especially Log4j!)
- Implement Web Application Firewall (WAF)
- Monitor for suspicious network activity
- Segment your network to limit damage
- Regular security assessments

The vulnerabilities I found make these attacks very feasible. **Act quickly to secure your systems!**"""
        
        elif any(word in user_lower for word in ['priority', 'first', 'order']):
            return f"""üéØ **VULNERABILITY PRIORITIZATION FOR {target_info.get('website', 'YOUR WEBSITE')}**

**Fix in this order:**

1Ô∏è‚É£ **CRITICAL PRIORITY** ({severity_summary.get('Critical', 0)} vulnerabilities)
   ‚è∞ Timeline: **Immediate (0-24 hours)**
   üí• Impact: Complete system compromise possible

2Ô∏è‚É£ **HIGH PRIORITY** ({severity_summary.get('High', 0)} vulnerabilities)  
   ‚è∞ Timeline: **1-7 days**
   üí• Impact: Significant security breach risk

3Ô∏è‚É£ **MEDIUM PRIORITY** ({severity_summary.get('Medium', 0)} vulnerabilities)
   ‚è∞ Timeline: **1-4 weeks** 
   üí• Impact: Moderate security risk

**Prioritization Factors:**
- CVSS score (higher = more urgent)
- Public exploit availability
- Internet-facing services
- Business criticality

Focus on the critical and high-severity issues first - they pose the greatest immediate threat to your organization."""
        
        else:
            # Generic helpful response
            return f"""I'm here to help you understand and fix the security vulnerabilities found in **{target_info.get('website', 'your website')}**.

**Quick Summary:**
- üéØ Target analyzed: {target_info.get('website', 'Unknown')}
- üîç Total vulnerabilities: {target_info.get('total_vulnerabilities', 0)}
- üö® Risk level: {"HIGH" if severity_summary.get('Critical', 0) > 0 else "MEDIUM" if severity_summary.get('High', 0) > 0 else "LOW"}

**I can help you with:**
- üîç Explaining specific vulnerabilities (try "tell me about CVE-2021-44228")
- üõ†Ô∏è Step-by-step remediation guidance (ask "how do I fix this?")
- üéØ Risk prioritization (ask "what should I fix first?")
- üï∏Ô∏è Attack scenario analysis (ask "how could this be exploited?")

**What would you like to know?** Just ask me in plain English!"""
    
    def process_query(self, user_message: str) -> str:
        """Process user query using AI or intelligent fallback"""
        
        # Add to conversation history
        self.conversation_history.append({
            'timestamp': datetime.now().isoformat(),
            'user_message': user_message,
            'ai_provider': self.ai_provider
        })
        
        # Add to context window for AI
        self.context_window.append({"role": "user", "content": user_message})
        
        # Get AI response
        if self.ai_provider == 'openai':
            response = self._call_openai_api(user_message)
        elif self.ai_provider == 'anthropic':
            response = self._call_anthropic_api(user_message)
        elif self.ai_provider == 'gemini':
            response = self._call_gemini_api(user_message)
        else:
            response = self._fallback_response(user_message)
        
        # Add response to context window
        self.context_window.append({"role": "assistant", "content": response})
        
        # Keep context window manageable (last 10 messages)
        if len(self.context_window) > 10:
            self.context_window = self.context_window[-10:]
        
        return response
    
    def start_interactive_session(self):
        """Start interactive AI chatbot session"""
        print("="*80)
        print("ü§ñ SECURECHAIN AI - INTELLIGENT VULNERABILITY CONSULTANT")
        print("="*80)
        
        # Show AI provider status
        if self.ai_provider != 'fallback':
            print(f"üß† AI Provider: {self.ai_provider.upper()} (Intelligent responses enabled)")
        else:
            print("‚ö†Ô∏è  AI Provider: Fallback mode (Set OPENAI_API_KEY, ANTHROPIC_API_KEY, or GEMINI_API_KEY for full AI)")
        
        print("\n" + self.process_query("hello"))
        print("\nType 'quit' or 'exit' to end the session.")
        print("="*80)
        
        while True:
            try:
                user_input = input("\nüí¨ You: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'bye']:
                    print("\nüëã Thank you for using SecureChain AI! Stay secure!")
                    break
                
                if not user_input:
                    print("Please enter a question or type 'quit' to exit.")
                    continue
                
                print("\nü§ñ SecureChain AI: ", end="")
                
                # Show thinking indicator for AI responses
                if self.ai_provider != 'fallback':
                    print("(thinking...)", end="", flush=True)
                    print("\rü§ñ SecureChain AI: ", end="")
                
                response = self.process_query(user_input)
                print(response)
                
            except KeyboardInterrupt:
                print("\n\nüëã Session ended. Stay secure!")
                break
            except Exception as e:
                logger.error(f"Error processing query: {e}")
                print(f"\n‚ùå I encountered an error. Please try rephrasing your question.")

def main():
    """Main function"""
    print("üöÄ Starting SecureChain AI-Powered Vulnerability Chatbot...")
    
    # Check for API keys
    api_keys_available = []
    if os.getenv('OPENAI_API_KEY'):
        api_keys_available.append('OpenAI GPT')
    if os.getenv('ANTHROPIC_API_KEY'):
        api_keys_available.append('Anthropic Claude')
    if os.getenv('GEMINI_API_KEY'):
        api_keys_available.append('Google Gemini')
    
    if api_keys_available:
        print(f"‚úÖ AI Models Available: {', '.join(api_keys_available)}")
    else:
        print("‚ö†Ô∏è  No AI API keys found. Using intelligent fallback mode.")
        print("   Set OPENAI_API_KEY, ANTHROPIC_API_KEY, or GEMINI_API_KEY for full AI capabilities.")
    
    # Get knowledge base file
    if len(sys.argv) > 1:
        kb_file = sys.argv[1]
    else:
        # Look for the most recent knowledge base file
        kb_files = list(Path(".").glob("*_chatbot_kb.json"))
        if kb_files:
            kb_file = str(sorted(kb_files)[-1])  # Most recent
            print(f"üìö Using knowledge base: {kb_file}")
        else:
            print("‚ùå No knowledge base file found.")
            print("   Please run: python complete_website_analysis.py <website> first")
            sys.exit(1)
    
    try:
        chatbot = AIVulnerabilityChatbot(kb_file)
        chatbot.start_interactive_session()
    except Exception as e:
        logger.error(f"Error starting chatbot: {e}")
        print(f"‚ùå Error starting chatbot: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()